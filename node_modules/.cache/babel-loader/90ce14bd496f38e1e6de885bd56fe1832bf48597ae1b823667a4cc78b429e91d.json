{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket, filename, options) {\n    super();\n    /**\n     * The document containing information about the inserted file.\n     * This property is defined _after_ the finish event has been emitted.\n     * It will remain `null` if an error occurs.\n     *\n     * @example\n     * ```ts\n     * fs.createReadStream('file.txt')\n     *   .pipe(bucket.openUploadStream('file.txt'))\n     *   .on('finish', function () {\n     *     console.log(this.gridFSFile)\n     *   })\n     * ```\n     */\n    this.gridFSFile = null;\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this).then(() => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      }, () => null);\n    }\n  }\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  _construct(callback) {\n    if (this.bucket.s.checkedIndexes) {\n      return process.nextTick(callback);\n    }\n    this.bucket.once('index', callback);\n  }\n  /**\n   * @internal\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   */\n  _write(chunk, encoding, callback) {\n    doWrite(this, chunk, encoding, callback);\n  }\n  /** @internal */\n  _final(callback) {\n    if (this.state.streamEnd) {\n      return process.nextTick(callback);\n    }\n    this.state.streamEnd = true;\n    writeRemnant(this, callback);\n  }\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort() {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n    }\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n    }\n    this.state.aborted = true;\n    await this.chunks.deleteMany({\n      files_id: this.id\n    });\n  }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\nasync function checkChunksIndex(stream) {\n  const index = {\n    files_id: 1,\n    n: 1\n  };\n  let indexes;\n  try {\n    indexes = await stream.chunks.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasChunksIndex) {\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true\n    });\n  }\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (isAborted(stream, callback)) {\n      return;\n    }\n    stream.files.insertOne(gridFSFile, {\n      writeConcern: stream.writeConcern\n    }).then(() => {\n      stream.gridFSFile = gridFSFile;\n      callback();\n    }, error => handleError(stream, error, callback));\n    return;\n  }\n  process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n  const doc = await stream.files.findOne({}, {\n    projection: {\n      _id: 1\n    }\n  });\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n  const index = {\n    filename: 1,\n    uploadDate: 1\n  };\n  let indexes;\n  try {\n    indexes = await stream.files.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasFileIndex) {\n    await stream.files.createIndex(index, {\n      background: false\n    });\n  }\n  await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (isAborted(stream, callback)) {\n        return;\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern\n      }).then(() => {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          checkDone(stream, callback);\n        }\n      }, error => handleError(stream, error, callback));\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  ++stream.state.outstandingRequests;\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern\n  }).then(() => {\n    --stream.state.outstandingRequests;\n    checkDone(stream, callback);\n  }, error => handleError(stream, error, callback));\n}\nfunction isAborted(stream, callback) {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}","map":{"version":3,"names":["Object","defineProperty","exports","value","GridFSBucketWriteStream","stream_1","require","bson_1","error_1","write_concern_1","Writable","constructor","bucket","filename","options","gridFSFile","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","WriteConcern","fromOptions","done","id","ObjectId","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","then","checkedIndexes","emit","_construct","callback","process","nextTick","once","_write","chunk","encoding","doWrite","_final","writeRemnant","abort","MongoAPIError","deleteMany","files_id","handleError","stream","error","createChunkDoc","filesId","data","_id","checkChunksIndex","index","indexes","listIndexes","toArray","MongoError","code","MONGODB_ERROR_CODES","NamespaceNotFound","hasChunksIndex","find","keys","key","createIndex","background","unique","checkDone","createFilesDoc","contentType","aliases","metadata","isAborted","insertOne","doc","findOne","projection","uploadDate","hasFileIndex","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","remnant"],"sources":["D:/web_project/node_modules/mongodb/lib/gridfs/upload.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /**\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     * @internal\n     */\n    constructor(bucket, filename, options) {\n        super();\n        /**\n         * The document containing information about the inserted file.\n         * This property is defined _after_ the finish event has been emitted.\n         * It will remain `null` if an error occurs.\n         *\n         * @example\n         * ```ts\n         * fs.createReadStream('file.txt')\n         *   .pipe(bucket.openUploadStream('file.txt'))\n         *   .on('finish', function () {\n         *     console.log(this.gridFSFile)\n         *   })\n         * ```\n         */\n        this.gridFSFile = null;\n        options = options ?? {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            checkIndexes(this).then(() => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            }, () => null);\n        }\n    }\n    /**\n     * @internal\n     *\n     * The stream is considered constructed when the indexes are done being created\n     */\n    _construct(callback) {\n        if (this.bucket.s.checkedIndexes) {\n            return process.nextTick(callback);\n        }\n        this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n    _write(chunk, encoding, callback) {\n        doWrite(this, chunk, encoding, callback);\n    }\n    /** @internal */\n    _final(callback) {\n        if (this.state.streamEnd) {\n            return process.nextTick(callback);\n        }\n        this.state.streamEnd = true;\n        writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n    async abort() {\n        if (this.state.streamEnd) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n        }\n        if (this.state.aborted) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n        }\n        this.state.aborted = true;\n        await this.chunks.deleteMany({ files_id: this.id });\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        process.nextTick(callback);\n        return;\n    }\n    stream.state.errored = true;\n    process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nasync function checkChunksIndex(stream) {\n    const index = { files_id: 1, n: 1 };\n    let indexes;\n    try {\n        indexes = await stream.chunks.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasChunksIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasChunksIndex) {\n        await stream.chunks.createIndex(index, {\n            ...stream.writeConcern,\n            background: true,\n            unique: true\n        });\n    }\n}\nfunction checkDone(stream, callback) {\n    if (stream.done) {\n        return process.nextTick(callback);\n    }\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (isAborted(stream, callback)) {\n            return;\n        }\n        stream.files.insertOne(gridFSFile, { writeConcern: stream.writeConcern }).then(() => {\n            stream.gridFSFile = gridFSFile;\n            callback();\n        }, error => handleError(stream, error, callback));\n        return;\n    }\n    process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n    const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n    if (doc != null) {\n        // If at least one document exists assume the collection has the required index\n        return;\n    }\n    const index = { filename: 1, uploadDate: 1 };\n    let indexes;\n    try {\n        indexes = await stream.files.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasFileIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasFileIndex) {\n        await stream.files.createIndex(index, { background: false });\n    }\n    await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        process.nextTick(callback);\n        return;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (isAborted(stream, callback)) {\n                return;\n            }\n            stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    checkDone(stream, callback);\n                }\n            }, error => handleError(stream, error, callback));\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n    }, error => handleError(stream, error, callback));\n}\nfunction isAborted(stream, callback) {\n    if (stream.state.aborted) {\n        process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=upload.js.map"],"mappings":"AAAA,YAAY;;AACZA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,uBAAuB,GAAG,KAAK,CAAC;AACxC,MAAMC,QAAQ,GAAGC,OAAO,CAAC,QAAQ,CAAC;AAClC,MAAMC,MAAM,GAAGD,OAAO,CAAC,SAAS,CAAC;AACjC,MAAME,OAAO,GAAGF,OAAO,CAAC,UAAU,CAAC;AACnC,MAAMG,eAAe,GAAGH,OAAO,CAAC,oBAAoB,CAAC;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,MAAMF,uBAAuB,SAASC,QAAQ,CAACK,QAAQ,CAAC;EACpD;AACJ;AACA;AACA;AACA;AACA;EACIC,WAAWA,CAACC,MAAM,EAAEC,QAAQ,EAAEC,OAAO,EAAE;IACnC,KAAK,CAAC,CAAC;IACP;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;IACQ,IAAI,CAACC,UAAU,GAAG,IAAI;IACtBD,OAAO,GAAGA,OAAO,IAAI,CAAC,CAAC;IACvB,IAAI,CAACF,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACI,MAAM,GAAGJ,MAAM,CAACK,CAAC,CAACC,iBAAiB;IACxC,IAAI,CAACL,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACM,KAAK,GAAGP,MAAM,CAACK,CAAC,CAACG,gBAAgB;IACtC,IAAI,CAACN,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACO,YAAY,GAAGZ,eAAe,CAACa,YAAY,CAACC,WAAW,CAACT,OAAO,CAAC,IAAIF,MAAM,CAACK,CAAC,CAACH,OAAO,CAACO,YAAY;IACtG;IACA,IAAI,CAACG,IAAI,GAAG,KAAK;IACjB,IAAI,CAACC,EAAE,GAAGX,OAAO,CAACW,EAAE,GAAGX,OAAO,CAACW,EAAE,GAAG,IAAIlB,MAAM,CAACmB,QAAQ,CAAC,CAAC;IACzD;IACA,IAAI,CAACC,cAAc,GAAGb,OAAO,CAACa,cAAc,IAAI,IAAI,CAACf,MAAM,CAACK,CAAC,CAACH,OAAO,CAACa,cAAc;IACpF,IAAI,CAACC,UAAU,GAAGC,MAAM,CAACC,KAAK,CAAC,IAAI,CAACH,cAAc,CAAC;IACnD,IAAI,CAACI,MAAM,GAAG,CAAC;IACf,IAAI,CAACC,CAAC,GAAG,CAAC;IACV,IAAI,CAACC,GAAG,GAAG,CAAC;IACZ,IAAI,CAACC,KAAK,GAAG;MACTC,SAAS,EAAE,KAAK;MAChBC,mBAAmB,EAAE,CAAC;MACtBC,OAAO,EAAE,KAAK;MACdC,OAAO,EAAE;IACb,CAAC;IACD,IAAI,CAAC,IAAI,CAAC1B,MAAM,CAACK,CAAC,CAACsB,sBAAsB,EAAE;MACvC,IAAI,CAAC3B,MAAM,CAACK,CAAC,CAACsB,sBAAsB,GAAG,IAAI;MAC3CC,YAAY,CAAC,IAAI,CAAC,CAACC,IAAI,CAAC,MAAM;QAC1B,IAAI,CAAC7B,MAAM,CAACK,CAAC,CAACyB,cAAc,GAAG,IAAI;QACnC,IAAI,CAAC9B,MAAM,CAAC+B,IAAI,CAAC,OAAO,CAAC;MAC7B,CAAC,EAAE,MAAM,IAAI,CAAC;IAClB;EACJ;EACA;AACJ;AACA;AACA;AACA;EACIC,UAAUA,CAACC,QAAQ,EAAE;IACjB,IAAI,IAAI,CAACjC,MAAM,CAACK,CAAC,CAACyB,cAAc,EAAE;MAC9B,OAAOI,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IACrC;IACA,IAAI,CAACjC,MAAM,CAACoC,IAAI,CAAC,OAAO,EAAEH,QAAQ,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACII,MAAMA,CAACC,KAAK,EAAEC,QAAQ,EAAEN,QAAQ,EAAE;IAC9BO,OAAO,CAAC,IAAI,EAAEF,KAAK,EAAEC,QAAQ,EAAEN,QAAQ,CAAC;EAC5C;EACA;EACAQ,MAAMA,CAACR,QAAQ,EAAE;IACb,IAAI,IAAI,CAACX,KAAK,CAACC,SAAS,EAAE;MACtB,OAAOW,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IACrC;IACA,IAAI,CAACX,KAAK,CAACC,SAAS,GAAG,IAAI;IAC3BmB,YAAY,CAAC,IAAI,EAAET,QAAQ,CAAC;EAChC;EACA;AACJ;AACA;AACA;EACI,MAAMU,KAAKA,CAAA,EAAG;IACV,IAAI,IAAI,CAACrB,KAAK,CAACC,SAAS,EAAE;MACtB;MACA,MAAM,IAAI3B,OAAO,CAACgD,aAAa,CAAC,kDAAkD,CAAC;IACvF;IACA,IAAI,IAAI,CAACtB,KAAK,CAACI,OAAO,EAAE;MACpB;MACA,MAAM,IAAI9B,OAAO,CAACgD,aAAa,CAAC,uCAAuC,CAAC;IAC5E;IACA,IAAI,CAACtB,KAAK,CAACI,OAAO,GAAG,IAAI;IACzB,MAAM,IAAI,CAACtB,MAAM,CAACyC,UAAU,CAAC;MAAEC,QAAQ,EAAE,IAAI,CAACjC;IAAG,CAAC,CAAC;EACvD;AACJ;AACAvB,OAAO,CAACE,uBAAuB,GAAGA,uBAAuB;AACzD,SAASuD,WAAWA,CAACC,MAAM,EAAEC,KAAK,EAAEhB,QAAQ,EAAE;EAC1C,IAAIe,MAAM,CAAC1B,KAAK,CAACG,OAAO,EAAE;IACtBS,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IAC1B;EACJ;EACAe,MAAM,CAAC1B,KAAK,CAACG,OAAO,GAAG,IAAI;EAC3BS,OAAO,CAACC,QAAQ,CAACF,QAAQ,EAAEgB,KAAK,CAAC;AACrC;AACA,SAASC,cAAcA,CAACC,OAAO,EAAE/B,CAAC,EAAEgC,IAAI,EAAE;EACtC,OAAO;IACHC,GAAG,EAAE,IAAI1D,MAAM,CAACmB,QAAQ,CAAC,CAAC;IAC1BgC,QAAQ,EAAEK,OAAO;IACjB/B,CAAC;IACDgC;EACJ,CAAC;AACL;AACA,eAAeE,gBAAgBA,CAACN,MAAM,EAAE;EACpC,MAAMO,KAAK,GAAG;IAAET,QAAQ,EAAE,CAAC;IAAE1B,CAAC,EAAE;EAAE,CAAC;EACnC,IAAIoC,OAAO;EACX,IAAI;IACAA,OAAO,GAAG,MAAMR,MAAM,CAAC5C,MAAM,CAACqD,WAAW,CAAC,CAAC,CAACC,OAAO,CAAC,CAAC;EACzD,CAAC,CACD,OAAOT,KAAK,EAAE;IACV,IAAIA,KAAK,YAAYrD,OAAO,CAAC+D,UAAU,IAAIV,KAAK,CAACW,IAAI,KAAKhE,OAAO,CAACiE,mBAAmB,CAACC,iBAAiB,EAAE;MACrGN,OAAO,GAAG,EAAE;IAChB,CAAC,MACI;MACD,MAAMP,KAAK;IACf;EACJ;EACA,MAAMc,cAAc,GAAG,CAAC,CAACP,OAAO,CAACQ,IAAI,CAACT,KAAK,IAAI;IAC3C,MAAMU,IAAI,GAAG7E,MAAM,CAAC6E,IAAI,CAACV,KAAK,CAACW,GAAG,CAAC;IACnC,IAAID,IAAI,CAAC9C,MAAM,KAAK,CAAC,IAAIoC,KAAK,CAACW,GAAG,CAACpB,QAAQ,KAAK,CAAC,IAAIS,KAAK,CAACW,GAAG,CAAC9C,CAAC,KAAK,CAAC,EAAE;MACpE,OAAO,IAAI;IACf;IACA,OAAO,KAAK;EAChB,CAAC,CAAC;EACF,IAAI,CAAC2C,cAAc,EAAE;IACjB,MAAMf,MAAM,CAAC5C,MAAM,CAAC+D,WAAW,CAACZ,KAAK,EAAE;MACnC,GAAGP,MAAM,CAACvC,YAAY;MACtB2D,UAAU,EAAE,IAAI;MAChBC,MAAM,EAAE;IACZ,CAAC,CAAC;EACN;AACJ;AACA,SAASC,SAASA,CAACtB,MAAM,EAAEf,QAAQ,EAAE;EACjC,IAAIe,MAAM,CAACpC,IAAI,EAAE;IACb,OAAOsB,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;EACrC;EACA,IAAIe,MAAM,CAAC1B,KAAK,CAACC,SAAS,IAAIyB,MAAM,CAAC1B,KAAK,CAACE,mBAAmB,KAAK,CAAC,IAAI,CAACwB,MAAM,CAAC1B,KAAK,CAACG,OAAO,EAAE;IAC3F;IACAuB,MAAM,CAACpC,IAAI,GAAG,IAAI;IAClB;IACA,MAAMT,UAAU,GAAGoE,cAAc,CAACvB,MAAM,CAACnC,EAAE,EAAEmC,MAAM,CAAC7B,MAAM,EAAE6B,MAAM,CAACjC,cAAc,EAAEiC,MAAM,CAAC/C,QAAQ,EAAE+C,MAAM,CAAC9C,OAAO,CAACsE,WAAW,EAAExB,MAAM,CAAC9C,OAAO,CAACuE,OAAO,EAAEzB,MAAM,CAAC9C,OAAO,CAACwE,QAAQ,CAAC;IAChL,IAAIC,SAAS,CAAC3B,MAAM,EAAEf,QAAQ,CAAC,EAAE;MAC7B;IACJ;IACAe,MAAM,CAACzC,KAAK,CAACqE,SAAS,CAACzE,UAAU,EAAE;MAAEM,YAAY,EAAEuC,MAAM,CAACvC;IAAa,CAAC,CAAC,CAACoB,IAAI,CAAC,MAAM;MACjFmB,MAAM,CAAC7C,UAAU,GAAGA,UAAU;MAC9B8B,QAAQ,CAAC,CAAC;IACd,CAAC,EAAEgB,KAAK,IAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAEhB,QAAQ,CAAC,CAAC;IACjD;EACJ;EACAC,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;AAC9B;AACA,eAAeL,YAAYA,CAACoB,MAAM,EAAE;EAChC,MAAM6B,GAAG,GAAG,MAAM7B,MAAM,CAACzC,KAAK,CAACuE,OAAO,CAAC,CAAC,CAAC,EAAE;IAAEC,UAAU,EAAE;MAAE1B,GAAG,EAAE;IAAE;EAAE,CAAC,CAAC;EACtE,IAAIwB,GAAG,IAAI,IAAI,EAAE;IACb;IACA;EACJ;EACA,MAAMtB,KAAK,GAAG;IAAEtD,QAAQ,EAAE,CAAC;IAAE+E,UAAU,EAAE;EAAE,CAAC;EAC5C,IAAIxB,OAAO;EACX,IAAI;IACAA,OAAO,GAAG,MAAMR,MAAM,CAACzC,KAAK,CAACkD,WAAW,CAAC,CAAC,CAACC,OAAO,CAAC,CAAC;EACxD,CAAC,CACD,OAAOT,KAAK,EAAE;IACV,IAAIA,KAAK,YAAYrD,OAAO,CAAC+D,UAAU,IAAIV,KAAK,CAACW,IAAI,KAAKhE,OAAO,CAACiE,mBAAmB,CAACC,iBAAiB,EAAE;MACrGN,OAAO,GAAG,EAAE;IAChB,CAAC,MACI;MACD,MAAMP,KAAK;IACf;EACJ;EACA,MAAMgC,YAAY,GAAG,CAAC,CAACzB,OAAO,CAACQ,IAAI,CAACT,KAAK,IAAI;IACzC,MAAMU,IAAI,GAAG7E,MAAM,CAAC6E,IAAI,CAACV,KAAK,CAACW,GAAG,CAAC;IACnC,IAAID,IAAI,CAAC9C,MAAM,KAAK,CAAC,IAAIoC,KAAK,CAACW,GAAG,CAACjE,QAAQ,KAAK,CAAC,IAAIsD,KAAK,CAACW,GAAG,CAACc,UAAU,KAAK,CAAC,EAAE;MAC7E,OAAO,IAAI;IACf;IACA,OAAO,KAAK;EAChB,CAAC,CAAC;EACF,IAAI,CAACC,YAAY,EAAE;IACf,MAAMjC,MAAM,CAACzC,KAAK,CAAC4D,WAAW,CAACZ,KAAK,EAAE;MAAEa,UAAU,EAAE;IAAM,CAAC,CAAC;EAChE;EACA,MAAMd,gBAAgB,CAACN,MAAM,CAAC;AAClC;AACA,SAASuB,cAAcA,CAAClB,GAAG,EAAElC,MAAM,EAAE+D,SAAS,EAAEjF,QAAQ,EAAEuE,WAAW,EAAEC,OAAO,EAAEC,QAAQ,EAAE;EACtF,MAAMS,GAAG,GAAG;IACR9B,GAAG;IACHlC,MAAM;IACN+D,SAAS;IACTF,UAAU,EAAE,IAAII,IAAI,CAAC,CAAC;IACtBnF;EACJ,CAAC;EACD,IAAIuE,WAAW,EAAE;IACbW,GAAG,CAACX,WAAW,GAAGA,WAAW;EACjC;EACA,IAAIC,OAAO,EAAE;IACTU,GAAG,CAACV,OAAO,GAAGA,OAAO;EACzB;EACA,IAAIC,QAAQ,EAAE;IACVS,GAAG,CAACT,QAAQ,GAAGA,QAAQ;EAC3B;EACA,OAAOS,GAAG;AACd;AACA,SAAS3C,OAAOA,CAACQ,MAAM,EAAEV,KAAK,EAAEC,QAAQ,EAAEN,QAAQ,EAAE;EAChD,IAAI0C,SAAS,CAAC3B,MAAM,EAAEf,QAAQ,CAAC,EAAE;IAC7B;EACJ;EACA,MAAMoD,QAAQ,GAAGpE,MAAM,CAACqE,QAAQ,CAAChD,KAAK,CAAC,GAAGA,KAAK,GAAGrB,MAAM,CAACsE,IAAI,CAACjD,KAAK,EAAEC,QAAQ,CAAC;EAC9ES,MAAM,CAAC7B,MAAM,IAAIkE,QAAQ,CAAClE,MAAM;EAChC;EACA,IAAI6B,MAAM,CAAC3B,GAAG,GAAGgE,QAAQ,CAAClE,MAAM,GAAG6B,MAAM,CAACjC,cAAc,EAAE;IACtDsE,QAAQ,CAACG,IAAI,CAACxC,MAAM,CAAChC,UAAU,EAAEgC,MAAM,CAAC3B,GAAG,CAAC;IAC5C2B,MAAM,CAAC3B,GAAG,IAAIgE,QAAQ,CAAClE,MAAM;IAC7Be,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IAC1B;EACJ;EACA;EACA;EACA,IAAIwD,iBAAiB,GAAGJ,QAAQ,CAAClE,MAAM;EACvC,IAAIuE,cAAc,GAAG1C,MAAM,CAACjC,cAAc,GAAGiC,MAAM,CAAC3B,GAAG;EACvD,IAAIsE,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAEL,QAAQ,CAAClE,MAAM,CAAC;EACzD,IAAIK,mBAAmB,GAAG,CAAC;EAC3B,OAAOiE,iBAAiB,GAAG,CAAC,EAAE;IAC1B,MAAMK,WAAW,GAAGT,QAAQ,CAAClE,MAAM,GAAGsE,iBAAiB;IACvDJ,QAAQ,CAACG,IAAI,CAACxC,MAAM,CAAChC,UAAU,EAAEgC,MAAM,CAAC3B,GAAG,EAAEyE,WAAW,EAAEA,WAAW,GAAGH,SAAS,CAAC;IAClF3C,MAAM,CAAC3B,GAAG,IAAIsE,SAAS;IACvBD,cAAc,IAAIC,SAAS;IAC3B,IAAId,GAAG;IACP,IAAIa,cAAc,KAAK,CAAC,EAAE;MACtBb,GAAG,GAAG3B,cAAc,CAACF,MAAM,CAACnC,EAAE,EAAEmC,MAAM,CAAC5B,CAAC,EAAEH,MAAM,CAACsE,IAAI,CAACvC,MAAM,CAAChC,UAAU,CAAC,CAAC;MACzE,EAAEgC,MAAM,CAAC1B,KAAK,CAACE,mBAAmB;MAClC,EAAEA,mBAAmB;MACrB,IAAImD,SAAS,CAAC3B,MAAM,EAAEf,QAAQ,CAAC,EAAE;QAC7B;MACJ;MACAe,MAAM,CAAC5C,MAAM,CAACwE,SAAS,CAACC,GAAG,EAAE;QAAEpE,YAAY,EAAEuC,MAAM,CAACvC;MAAa,CAAC,CAAC,CAACoB,IAAI,CAAC,MAAM;QAC3E,EAAEmB,MAAM,CAAC1B,KAAK,CAACE,mBAAmB;QAClC,EAAEA,mBAAmB;QACrB,IAAI,CAACA,mBAAmB,EAAE;UACtB8C,SAAS,CAACtB,MAAM,EAAEf,QAAQ,CAAC;QAC/B;MACJ,CAAC,EAAEgB,KAAK,IAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAEhB,QAAQ,CAAC,CAAC;MACjDyD,cAAc,GAAG1C,MAAM,CAACjC,cAAc;MACtCiC,MAAM,CAAC3B,GAAG,GAAG,CAAC;MACd,EAAE2B,MAAM,CAAC5B,CAAC;IACd;IACAqE,iBAAiB,IAAIE,SAAS;IAC9BA,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAED,iBAAiB,CAAC;EAC3D;AACJ;AACA,SAAS/C,YAAYA,CAACM,MAAM,EAAEf,QAAQ,EAAE;EACpC;EACA,IAAIe,MAAM,CAAC3B,GAAG,KAAK,CAAC,EAAE;IAClB,OAAOiD,SAAS,CAACtB,MAAM,EAAEf,QAAQ,CAAC;EACtC;EACA,EAAEe,MAAM,CAAC1B,KAAK,CAACE,mBAAmB;EAClC;EACA;EACA,MAAMuE,OAAO,GAAG9E,MAAM,CAACC,KAAK,CAAC8B,MAAM,CAAC3B,GAAG,CAAC;EACxC2B,MAAM,CAAChC,UAAU,CAACwE,IAAI,CAACO,OAAO,EAAE,CAAC,EAAE,CAAC,EAAE/C,MAAM,CAAC3B,GAAG,CAAC;EACjD,MAAMwD,GAAG,GAAG3B,cAAc,CAACF,MAAM,CAACnC,EAAE,EAAEmC,MAAM,CAAC5B,CAAC,EAAE2E,OAAO,CAAC;EACxD;EACA,IAAIpB,SAAS,CAAC3B,MAAM,EAAEf,QAAQ,CAAC,EAAE;IAC7B;EACJ;EACAe,MAAM,CAAC5C,MAAM,CAACwE,SAAS,CAACC,GAAG,EAAE;IAAEpE,YAAY,EAAEuC,MAAM,CAACvC;EAAa,CAAC,CAAC,CAACoB,IAAI,CAAC,MAAM;IAC3E,EAAEmB,MAAM,CAAC1B,KAAK,CAACE,mBAAmB;IAClC8C,SAAS,CAACtB,MAAM,EAAEf,QAAQ,CAAC;EAC/B,CAAC,EAAEgB,KAAK,IAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAEhB,QAAQ,CAAC,CAAC;AACrD;AACA,SAAS0C,SAASA,CAAC3B,MAAM,EAAEf,QAAQ,EAAE;EACjC,IAAIe,MAAM,CAAC1B,KAAK,CAACI,OAAO,EAAE;IACtBQ,OAAO,CAACC,QAAQ,CAACF,QAAQ,EAAE,IAAIrC,OAAO,CAACgD,aAAa,CAAC,yBAAyB,CAAC,CAAC;IAChF,OAAO,IAAI;EACf;EACA,OAAO,KAAK;AAChB","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}